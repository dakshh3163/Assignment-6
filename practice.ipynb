{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3204950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pymongo import MongoClient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c89e71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Page Title: Google\n",
      "Tag Name: title\n",
      "\n",
      "All found URLs:\n",
      "\n",
      "https://about.google/?fg=1&utm_source=google-IN&utm_medium=referral&utm_campaign=hp-header\n",
      "https://store.google.com/IN?utm_source=hp_header&utm_medium=google_ooo&utm_campaign=GS100042&hl=en-IN\n",
      "https://mail.google.com/mail/&ogbl\n",
      "https://www.google.com/imghp?hl=en&ogbl\n",
      "https://www.google.co.in/intl/en/about/products\n",
      "https://accounts.google.com/ServiceLogin?hl=en&passive=true&continue=https://www.google.com/&ec=futura_exp_og_so_72776762_e\n",
      "https://www.google.com/setprefs?sig=0_2NMF7clKURSWPfXn1iu1hEofHak%3D&hl=hi&source=homepage&sa=X&ved=0ahUKEwjOxLzqm4WRAxUjR2wGHTNIJZYQ2ZgBCBg\n",
      "https://www.google.com/setprefs?sig=0_2NMF7clKURSWPfXn1iu1hEofHak%3D&hl=bn&source=homepage&sa=X&ved=0ahUKEwjOxLzqm4WRAxUjR2wGHTNIJZYQ2ZgBCBk\n",
      "https://www.google.com/setprefs?sig=0_2NMF7clKURSWPfXn1iu1hEofHak%3D&hl=te&source=homepage&sa=X&ved=0ahUKEwjOxLzqm4WRAxUjR2wGHTNIJZYQ2ZgBCBo\n",
      "https://www.google.com/setprefs?sig=0_2NMF7clKURSWPfXn1iu1hEofHak%3D&hl=mr&source=homepage&sa=X&ved=0ahUKEwjOxLzqm4WRAxUjR2wGHTNIJZYQ2ZgBCBs\n",
      "https://www.google.com/setprefs?sig=0_2NMF7clKURSWPfXn1iu1hEofHak%3D&hl=ta&source=homepage&sa=X&ved=0ahUKEwjOxLzqm4WRAxUjR2wGHTNIJZYQ2ZgBCBw\n",
      "https://www.google.com/setprefs?sig=0_2NMF7clKURSWPfXn1iu1hEofHak%3D&hl=gu&source=homepage&sa=X&ved=0ahUKEwjOxLzqm4WRAxUjR2wGHTNIJZYQ2ZgBCB0\n",
      "https://www.google.com/setprefs?sig=0_2NMF7clKURSWPfXn1iu1hEofHak%3D&hl=kn&source=homepage&sa=X&ved=0ahUKEwjOxLzqm4WRAxUjR2wGHTNIJZYQ2ZgBCB4\n",
      "https://www.google.com/setprefs?sig=0_2NMF7clKURSWPfXn1iu1hEofHak%3D&hl=ml&source=homepage&sa=X&ved=0ahUKEwjOxLzqm4WRAxUjR2wGHTNIJZYQ2ZgBCB8\n",
      "https://www.google.com/setprefs?sig=0_2NMF7clKURSWPfXn1iu1hEofHak%3D&hl=pa&source=homepage&sa=X&ved=0ahUKEwjOxLzqm4WRAxUjR2wGHTNIJZYQ2ZgBCCA\n",
      "https://www.google.com/intl/en_in/ads/?subid=ww-ww-et-g-awa-a-g_hpafoot1_1!o2&utm_source=google.com&utm_medium=referral&utm_campaign=google_hpafooter&fg=1\n",
      "https://www.google.com/services/?subid=ww-ww-et-g-awa-a-g_hpbfoot1_1!o2&utm_source=google.com&utm_medium=referral&utm_campaign=google_hpbfooter&fg=1\n",
      "https://google.com/search/howsearchworks/?fg=1\n",
      "https://policies.google.com/privacy?hl=en-IN&fg=1\n",
      "https://policies.google.com/terms?hl=en-IN&fg=1\n",
      "https://www.google.com/preferences?hl=en-IN&fg=1\n",
      "/advanced_search?hl=en-IN&fg=1\n",
      "/history/privacyadvisor/search/unauth?utm_source=googlemenu&fg=1&cctld=com\n",
      "/history/optout?hl=en-IN&fg=1\n",
      "https://support.google.com/websearch/?p=ws_results_help&hl=en-IN&fg=1\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# Get website from user\n",
    "url = input(\"Enter a website to extract URLs from: \").strip()\n",
    "\n",
    "# Ensure it starts with http/https\n",
    "if not url.startswith((\"http://\", \"https://\")):\n",
    "    url = \"https://\" + url  # safer default\n",
    "\n",
    "# Set headers to avoid 403\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                  \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                  \"Chrome/124.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    # Fetch webpage\n",
    "    r = requests.get(url, headers=headers, timeout=10)\n",
    "    r.raise_for_status()  # raises error for 4xx/5xx\n",
    "\n",
    "    # Parse HTML\n",
    "    soup = BeautifulSoup(r.text, 'lxml')\n",
    "\n",
    "    # Extract and print title\n",
    "    if soup.title:\n",
    "        title = soup.title.string.strip()\n",
    "        tag_name = soup.title.name\n",
    "        print(f\"\\nPage Title: {title}\\nTag Name: {tag_name}\\n\")\n",
    "    else:\n",
    "        print(\"No title found.\\n\")\n",
    "\n",
    "    # Extract and print URLs\n",
    "    print(\"All found URLs:\\n\")\n",
    "    for link in soup.find_all('a', href=True):\n",
    "        print(link['href'])\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error fetching the site: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01b28e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not enough tables on the page.\n"
     ]
    }
   ],
   "source": [
    "url = 'http://www.usamega.com/mega-millions-history.asp?p=1'\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                  \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                  \"Chrome/124.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "req = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(req.text, 'lxml')  \n",
    "\n",
    "\n",
    "tables = soup.find_all('table')\n",
    "\n",
    "if len(tables) > 4:\n",
    "    rows = tables[4].find_all('tr')\n",
    "    if len(rows) > 1:\n",
    "        cells = rows[1].find_all('td')\n",
    "        if len(cells) > 3:\n",
    "            try:\n",
    "                draw_date = cells[1].a.string.strip() if cells[1].a else \"No link text\"\n",
    "                jackpot_b = cells[3].b.string.strip() if cells[3].b else \"No <b> tag\"\n",
    "                jackpot_strong = cells[3].strong.string.strip() if cells[3].strong else \"No <strong> tag\"\n",
    "                \n",
    "                print(\"Draw Date:\", draw_date)\n",
    "                print(\"Jackpot (b tag):\", jackpot_b)\n",
    "                print(\"Jackpot (strong tag):\", jackpot_strong)\n",
    "            except Exception as e:\n",
    "                print(\"Error extracting data:\", e)\n",
    "        else:\n",
    "            print(\"Not enough <td> elements in the row.\")\n",
    "    else:\n",
    "        print(\"Not enough rows in the table.\")\n",
    "else:\n",
    "    print(\"Not enough tables on the page.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcf6bab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1...\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "403 Client Error: Forbidden for url: https://www.usamega.com/mega-millions-history.asp?p=1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 74\u001b[39m\n\u001b[32m     71\u001b[39m             \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo data on page \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 66\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m page_num \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, total_pages + \u001b[32m1\u001b[39m):\n\u001b[32m     65\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mScraping page \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m     data = \u001b[43mscrape_page\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage_num\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[32m     68\u001b[39m         col.insert_many(data)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mscrape_page\u001b[39m\u001b[34m(page_num)\u001b[39m\n\u001b[32m     13\u001b[39m headers = {\n\u001b[32m     14\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mUser-Agent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mMozilla/5.0 (Windows NT 10.0; Win64; x64) \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     15\u001b[39m                   \u001b[33m\"\u001b[39m\u001b[33mAppleWebKit/537.36 (KHTML, like Gecko) \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     16\u001b[39m                   \u001b[33m\"\u001b[39m\u001b[33mChrome/124.0.0.0 Safari/537.36\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     17\u001b[39m }\n\u001b[32m     19\u001b[39m response = requests.get(url, headers=headers)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m soup = BeautifulSoup(response.text, \u001b[33m\"\u001b[39m\u001b[33mlxml\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     23\u001b[39m tables = soup.find_all(\u001b[33m\"\u001b[39m\u001b[33mtable\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\daksh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\models.py:1026\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1021\u001b[39m     http_error_msg = (\n\u001b[32m   1022\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1023\u001b[39m     )\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 403 Client Error: Forbidden for url: https://www.usamega.com/mega-millions-history.asp?p=1"
     ]
    }
   ],
   "source": [
    "# MongoDB setup\n",
    "MONGO_URI = \"mongodb://localhost:27017/\"\n",
    "DATABASE = \"lotto\"\n",
    "COLLECTION = \"mega_millions\"\n",
    "\n",
    "def mongo_connection():\n",
    "    client = MongoClient(MONGO_URI)\n",
    "    col = client[DATABASE][COLLECTION]\n",
    "    return col\n",
    "\n",
    "def scrape_page(page_num):\n",
    "    url = f\"https://www.usamega.com/mega-millions-history.asp?p={page_num}\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                      \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                      \"Chrome/124.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    soup = BeautifulSoup(response.text, \"lxml\")\n",
    "\n",
    "    tables = soup.find_all(\"table\")\n",
    "    if len(tables) < 5:\n",
    "        print(f\"Page {page_num}: expected table not found.\")\n",
    "        return []\n",
    "\n",
    "    rows = tables[4].find_all(\"tr\")\n",
    "    results = []\n",
    "\n",
    "    for row in rows[1:]:  # skip header\n",
    "        tds = row.find_all(\"td\")\n",
    "        if len(tds) < 4:\n",
    "            continue\n",
    "\n",
    "        draw_link = tds[1].find(\"a\")\n",
    "        jackpot_cell = tds[3]\n",
    "\n",
    "        if not draw_link or not jackpot_cell:\n",
    "            continue\n",
    "\n",
    "        draw_date = draw_link.get_text(strip=True)\n",
    "        numbers_text = jackpot_cell.find(\"b\")\n",
    "        mega_text = jackpot_cell.find(\"strong\")\n",
    "\n",
    "        if not numbers_text or not mega_text:\n",
    "            continue\n",
    "\n",
    "        # Split numbers, BeautifulSoup already decodes &middot;\n",
    "        numbers = [int(n) for n in numbers_text.get_text(strip=True).split(\"·\")]\n",
    "        mega_number = int(mega_text.get_text(strip=True))\n",
    "\n",
    "        results.append({\n",
    "            \"date\": draw_date,\n",
    "            \"numbers\": numbers,\n",
    "            \"mega_number\": mega_number\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    col = mongo_connection()\n",
    "    total_pages = 63\n",
    "\n",
    "    for page_num in range(1, total_pages + 1):\n",
    "        print(f\"Scraping page {page_num}...\")\n",
    "        data = scrape_page(page_num)\n",
    "        if data:\n",
    "            col.insert_many(data)\n",
    "            print(f\"Inserted {len(data)} records from page {page_num}\")\n",
    "        else:\n",
    "            print(f\"No data on page {page_num}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f168de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted IDs: [ObjectId('692163da095d3dd71747d9bf'), ObjectId('692163da095d3dd71747d9c0'), ObjectId('692163da095d3dd71747d9c1')]\n",
      "{'_id': ObjectId('6903766be55cf07cfaf09fd3'), 'date': '2025-10-18', 'numbers': [7, 16, 24, 39, 42], 'mega_number': 6}\n",
      "{'_id': ObjectId('6903766be55cf07cfaf09fd1'), 'date': '2025-10-25', 'numbers': [5, 12, 28, 36, 48], 'mega_number': 17}\n",
      "{'_id': ObjectId('6903766be55cf07cfaf09fd2'), 'date': '2025-10-22', 'numbers': [1, 8, 19, 32, 45], 'mega_number': 10}\n",
      "{'_id': ObjectId('692163da095d3dd71747d9bf'), 'date': '2025-10-25', 'numbers': [5, 12, 28, 36, 48], 'mega_number': 17}\n",
      "{'_id': ObjectId('692163da095d3dd71747d9c0'), 'date': '2025-10-22', 'numbers': [1, 8, 19, 32, 45], 'mega_number': 10}\n",
      "{'_id': ObjectId('692163da095d3dd71747d9c1'), 'date': '2025-10-18', 'numbers': [7, 16, 24, 39, 42], 'mega_number': 6}\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "# Connect to your Atlas cluster\n",
    "uri = \"MONGO_DB_URL\"\n",
    "client = MongoClient(uri)\n",
    "\n",
    "# Select database and collection\n",
    "db = client[\"lotto\"]\n",
    "collection = db[\"mega_millions\"]\n",
    "\n",
    "# Example data to insert\n",
    "draws = [\n",
    "    {\n",
    "        \"date\": \"2025-10-25\",\n",
    "        \"numbers\": [5, 12, 28, 36, 48],\n",
    "        \"mega_number\": 17\n",
    "    },\n",
    "    {\n",
    "        \"date\": \"2025-10-22\",\n",
    "        \"numbers\": [1, 8, 19, 32, 45],\n",
    "        \"mega_number\": 10\n",
    "    },\n",
    "    {\n",
    "        \"date\": \"2025-10-18\",\n",
    "        \"numbers\": [7, 16, 24, 39, 42],\n",
    "        \"mega_number\": 6\n",
    "    }\n",
    "]\n",
    "\n",
    "# Insert multiple documents\n",
    "result = collection.insert_many(draws)\n",
    "print(\"Inserted IDs:\", result.inserted_ids)\n",
    "\n",
    "# Optional: verify insertion\n",
    "for doc in collection.find():\n",
    "    print(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "796d0b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during fetching/inserting: Could not find draw date element\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pymongo import MongoClient\n",
    "import datetime\n",
    "\n",
    "# === Configuration ===\n",
    "MONGO_URI = \"MONGO_DB_URL\"\n",
    "DATABASE = \"lotto\"\n",
    "COLLECTION = \"mega_millions\"\n",
    "# Website that lists the latest Mega Millions results\n",
    "RESULTS_URL = \"https://en.wikipedia.org/wiki/Computer\"  # example source\n",
    "\n",
    "# === Database connection ===\n",
    "client = MongoClient(MONGO_URI)\n",
    "db = client[DATABASE]\n",
    "col = db[COLLECTION]\n",
    "\n",
    "# === Function to fetch latest draw ===\n",
    "def fetch_latest_draw():\n",
    "    resp = requests.get(RESULTS_URL, headers={\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                      \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                      \"Chrome/124.0.0.0 Safari/537.36\"\n",
    "    }, timeout=10)\n",
    "    resp.raise_for_status()\n",
    "\n",
    "    soup = BeautifulSoup(resp.text, \"lxml\")\n",
    "\n",
    "    # Example: from lotteryusa page we might extract first draw info\n",
    "    # (This part **must** be adapted to the actual HTML structure)\n",
    "    # For example: the latest draw date might be in a <div> with class “results__header” etc\n",
    "    # Here we make a guess:\n",
    "    date_div = soup.select_one(\"section.results-section h3\")  # this is speculative\n",
    "    if not date_div:\n",
    "        raise RuntimeError(\"Could not find draw date element\")\n",
    "\n",
    "    draw_date_str = date_div.get_text(strip=True)\n",
    "    # parse date (depends on format)\n",
    "    draw_date = datetime.datetime.strptime(draw_date_str, \"%A, %b %d, %Y\")  # adjust format accordingly\n",
    "\n",
    "    numbers_div = soup.select_one(\"ul.drawresult-numbers\")  # speculative selector\n",
    "    if not numbers_div:\n",
    "        raise RuntimeError(\"Could not find numbers element\")\n",
    "\n",
    "    number_spans = numbers_div.find_all(\"li\")\n",
    "    # We expect 5 white + 1 mega ball\n",
    "    if len(number_spans) < 6:\n",
    "        raise RuntimeError(\"Unexpected numbers count\")\n",
    "\n",
    "    whites = [int(span.get_text()) for span in number_spans[:5]]\n",
    "    mega_ball = int(number_spans[5].get_text())\n",
    "\n",
    "    return {\n",
    "        \"date\": draw_date.strftime(\"%Y-%m-%d\"),\n",
    "        \"numbers\": whites,\n",
    "        \"mega_number\": mega_ball\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        draw = fetch_latest_draw()\n",
    "        print(\"Fetched draw:\", draw)\n",
    "\n",
    "        # Check if we already have this draw in DB\n",
    "        existing = col.find_one({\"date\": draw[\"date\"]})\n",
    "        if existing:\n",
    "            print(\"Draw for date\", draw[\"date\"], \"already in database. Skipping insert.\")\n",
    "        else:\n",
    "            result = col.insert_one(draw)\n",
    "            print(\"Inserted draw with _id:\", result.inserted_id)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error during fetching/inserting:\", e)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf9ae191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
       "&lt;html&gt;\n",
       "&lt;head&gt;\n",
       "    \n",
       "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://code.jquery.com/jquery-3.7.1.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap-glyphicons.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
       "    \n",
       "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
       "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
       "            &lt;style&gt;\n",
       "                #map_c6036cddafbeb8c308af537c65b97fdd {\n",
       "                    position: relative;\n",
       "                    width: 100.0%;\n",
       "                    height: 100.0%;\n",
       "                    left: 0.0%;\n",
       "                    top: 0.0%;\n",
       "                }\n",
       "                .leaflet-container { font-size: 1rem; }\n",
       "            &lt;/style&gt;\n",
       "\n",
       "            &lt;style&gt;html, body {\n",
       "                width: 100%;\n",
       "                height: 100%;\n",
       "                margin: 0;\n",
       "                padding: 0;\n",
       "            }\n",
       "            &lt;/style&gt;\n",
       "\n",
       "            &lt;style&gt;#map {\n",
       "                position:absolute;\n",
       "                top:0;\n",
       "                bottom:0;\n",
       "                right:0;\n",
       "                left:0;\n",
       "                }\n",
       "            &lt;/style&gt;\n",
       "\n",
       "            &lt;script&gt;\n",
       "                L_NO_TOUCH = false;\n",
       "                L_DISABLE_3D = false;\n",
       "            &lt;/script&gt;\n",
       "\n",
       "        \n",
       "&lt;/head&gt;\n",
       "&lt;body&gt;\n",
       "    \n",
       "    \n",
       "            &lt;div class=&quot;folium-map&quot; id=&quot;map_c6036cddafbeb8c308af537c65b97fdd&quot; &gt;&lt;/div&gt;\n",
       "        \n",
       "&lt;/body&gt;\n",
       "&lt;script&gt;\n",
       "    \n",
       "    \n",
       "            var map_c6036cddafbeb8c308af537c65b97fdd = L.map(\n",
       "                &quot;map_c6036cddafbeb8c308af537c65b97fdd&quot;,\n",
       "                {\n",
       "                    center: [35.0, 100.0],\n",
       "                    crs: L.CRS.EPSG3857,\n",
       "                    ...{\n",
       "  &quot;zoom&quot;: 4,\n",
       "  &quot;zoomControl&quot;: true,\n",
       "  &quot;preferCanvas&quot;: false,\n",
       "}\n",
       "\n",
       "                }\n",
       "            );\n",
       "\n",
       "            \n",
       "\n",
       "        \n",
       "    \n",
       "            var tile_layer_b919297715122e722cd8288c9fa7f0bb = L.tileLayer(\n",
       "                &quot;https://tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
       "                {\n",
       "  &quot;minZoom&quot;: 0,\n",
       "  &quot;maxZoom&quot;: 19,\n",
       "  &quot;maxNativeZoom&quot;: 19,\n",
       "  &quot;noWrap&quot;: false,\n",
       "  &quot;attribution&quot;: &quot;\\u0026copy; \\u003ca href=\\&quot;https://www.openstreetmap.org/copyright\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e contributors&quot;,\n",
       "  &quot;subdomains&quot;: &quot;abc&quot;,\n",
       "  &quot;detectRetina&quot;: false,\n",
       "  &quot;tms&quot;: false,\n",
       "  &quot;opacity&quot;: 1,\n",
       "}\n",
       "\n",
       "            );\n",
       "        \n",
       "    \n",
       "            tile_layer_b919297715122e722cd8288c9fa7f0bb.addTo(map_c6036cddafbeb8c308af537c65b97fdd);\n",
       "        \n",
       "    \n",
       "            var marker_f31e4ae56a0fb855832ab548430b31b5 = L.marker(\n",
       "                [37.7749, -122.4194],\n",
       "                {\n",
       "}\n",
       "            ).addTo(map_c6036cddafbeb8c308af537c65b97fdd);\n",
       "        \n",
       "    \n",
       "        var popup_67d4a285de186da34542a961fcf7fcde = L.popup({\n",
       "  &quot;maxWidth&quot;: &quot;100%&quot;,\n",
       "});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_af91d0cdd1f121ed75125bc7a04a7611 = $(`&lt;div id=&quot;html_af91d0cdd1f121ed75125bc7a04a7611&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Alice, age: 25&lt;/div&gt;`)[0];\n",
       "                popup_67d4a285de186da34542a961fcf7fcde.setContent(html_af91d0cdd1f121ed75125bc7a04a7611);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_f31e4ae56a0fb855832ab548430b31b5.bindPopup(popup_67d4a285de186da34542a961fcf7fcde)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_ae9e4f0a78a80f4098b074c434fe6743 = L.marker(\n",
       "                [34.0522, -118.2437],\n",
       "                {\n",
       "}\n",
       "            ).addTo(map_c6036cddafbeb8c308af537c65b97fdd);\n",
       "        \n",
       "    \n",
       "        var popup_e124e26824231910d07f1eb59e156936 = L.popup({\n",
       "  &quot;maxWidth&quot;: &quot;100%&quot;,\n",
       "});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_84261944b77d589be494de575f311fc5 = $(`&lt;div id=&quot;html_84261944b77d589be494de575f311fc5&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Bob, age: 30&lt;/div&gt;`)[0];\n",
       "                popup_e124e26824231910d07f1eb59e156936.setContent(html_84261944b77d589be494de575f311fc5);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_ae9e4f0a78a80f4098b074c434fe6743.bindPopup(popup_e124e26824231910d07f1eb59e156936)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_6caf89a47dee7bd5cdf32c29603ad025 = L.marker(\n",
       "                [31.2304, 121.4737],\n",
       "                {\n",
       "}\n",
       "            ).addTo(map_c6036cddafbeb8c308af537c65b97fdd);\n",
       "        \n",
       "    \n",
       "        var popup_202c0a0ba5e849d5b891de8b58a98380 = L.popup({\n",
       "  &quot;maxWidth&quot;: &quot;100%&quot;,\n",
       "});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_1e8dc15b1ca60808514be37d2ce91203 = $(`&lt;div id=&quot;html_1e8dc15b1ca60808514be37d2ce91203&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Charlie, age: 22&lt;/div&gt;`)[0];\n",
       "                popup_202c0a0ba5e849d5b891de8b58a98380.setContent(html_1e8dc15b1ca60808514be37d2ce91203);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_6caf89a47dee7bd5cdf32c29603ad025.bindPopup(popup_202c0a0ba5e849d5b891de8b58a98380)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            tile_layer_b919297715122e722cd8288c9fa7f0bb.addTo(map_c6036cddafbeb8c308af537c65b97fdd);\n",
       "        \n",
       "&lt;/script&gt;\n",
       "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x19b37ce6d90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "\n",
    "# Example data\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'Age': [25, 30, 22],\n",
    "    'Location': ['37.7749,-122.4194', '34.0522,-118.2437', '31.2304,121.4737']\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df2 = pd.DataFrame(data)\n",
    "\n",
    "# Create base map\n",
    "world_map = folium.Map(location=[35, 100], zoom_start=4)\n",
    "\n",
    "# Add markers\n",
    "for i in range(len(df2)):\n",
    "    lat, lon = map(float, df2.Location[i].split(','))\n",
    "    popup_text = f\"{df2.Name[i]}, age: {df2.Age[i]}\"\n",
    "    folium.Marker(location=[lat, lon], popup=popup_text).add_to(world_map)\n",
    "\n",
    "# Display the map (in Jupyter) or save to file\n",
    "world_map.save(\"world_map.html\")\n",
    "world_map\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
